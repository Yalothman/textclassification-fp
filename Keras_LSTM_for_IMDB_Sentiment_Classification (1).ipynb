{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JnRNQdXzRukt"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load your dataset\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "hoR88TdeSU9D",
        "outputId": "fc6b9599-e810-4908-f19e-b954a388c04d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a6a37732-2a67-45c4-b416-777a37bca0bc\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-a6a37732-2a67-45c4-b416-777a37bca0bc\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving RCA_V3.csv to RCA_V3.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data = (pd.read_csv('RCA_V3.csv',sep=None,engine='python', usecols = ['RCA_Main_Root_Cause','RCA Defect Domain'])).dropna(how='all')\n",
        "\n",
        "\n",
        "# Inspect the dataframe columns\n",
        "print(\"Data columns:\", data.columns)\n",
        "\n",
        "# Rename columns for consistency\n",
        "data.columns = ['text', 'label']\n",
        "\n",
        "# Ensure the column names are correct\n",
        "print(\"Renamed data columns:\", data.columns)\n",
        "\n",
        "# Check for NaN values\n",
        "print(\"Number of NaN values in text column:\", data['text'].isna().sum())\n",
        "print(\"Number of NaN values in label column:\", data['label'].isna().sum())\n",
        "\n",
        "# Drop NaN values if any\n",
        "data = data.dropna(subset=['text', 'label'])\n",
        "\n",
        "# Preprocess the text data\n",
        "texts = data['text'].astype(str).values  # Convert all entries to strings\n",
        "\n",
        "#labels = data['label'].values\n",
        "# Label encode the labels\n",
        "label_encoder = LabelEncoder()\n",
        "labels = label_encoder.fit_transform(data['label'].astype(str).values)  # Convert labels to numeric\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Had-RE5QSU_O",
        "outputId": "7b8277e2-2d9a-4e60-a365-0f61353f2061"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data columns: Index(['RCA_Main_Root_Cause', 'RCA Defect Domain'], dtype='object')\n",
            "Renamed data columns: Index(['text', 'label'], dtype='object')\n",
            "Number of NaN values in text column: 316\n",
            "Number of NaN values in label column: 264\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure all labels are integers\n",
        "print(\"Encoded labels:\", labels)\n",
        "print(\"Unique labels:\", np.unique(labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_EpxScSYI67",
        "outputId": "28f52f6e-555b-412b-f90c-05a3f22c2e9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoded labels: [0 0 2 ... 4 0 3]\n",
            "Unique labels: [0 1 2 3 4 5 6 7 8]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the text data\n",
        "max_features = 20000\n",
        "maxlen = 80  # cut texts after this number of words\n",
        "tokenizer = Tokenizer(num_words=max_features)\n",
        "tokenizer.fit_on_texts(texts)\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n"
      ],
      "metadata": {
        "id": "nY7szIc7SVC2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pad sequences\n",
        "x_data = pad_sequences(sequences, maxlen=maxlen)\n"
      ],
      "metadata": {
        "id": "YGeOksvBSVFx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert labels to numpy array\n",
        "y_data = np.array(labels)"
      ],
      "metadata": {
        "id": "68ua66XpSVPJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify data types\n",
        "print(f\"x_data type: {x_data.dtype}, y_data type: {y_data.dtype}\")\n",
        "print(f\"x_data shape: {x_data.shape}, y_data shape: {y_data.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ggcYw4nabPu",
        "outputId": "835c9e84-33e0-4021-c9f8-4ff2e72bf784"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_data type: int32, y_data type: object\n",
            "x_data shape: (10521, 80), y_data shape: (10521,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure there are no float types in y_data\n",
        "print(f\"y_data type after conversion: {y_data.dtype}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGidAZ9kcXlh",
        "outputId": "ddcee4fc-5694-48c7-9ee8-6e2d66889035"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_data type after conversion: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into training and testing sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "eg0fUp2tSVQM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify data types\n",
        "print(f\"x_data type: {x_data.dtype}, y_data type: {y_data.dtype}\")\n",
        "print(f\"x_data shape: {x_data.shape}, y_data shape: {y_data.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XnTLf3McaTbW",
        "outputId": "cb8187ec-e335-40ac-88e9-83321e0e2122"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_data type: int32, y_data type: object\n",
            "x_data shape: (10521, 80), y_data shape: (10521,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure training and testing sets are of correct types\n",
        "print(f\"x_train type: {x_train.dtype}, y_train type: {y_train.dtype}\")\n",
        "print(f\"x_test type: {x_test.dtype}, y_test type: {y_test.dtype}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwz1wz3rYkZ_",
        "outputId": "c030b314-3fc6-4a22-a7f3-db14c21d9388"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train type: int32, y_train type: object\n",
            "x_test type: int32, y_test type: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the LSTM model\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_features, 128, input_length=maxlen))\n",
        "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n"
      ],
      "metadata": {
        "id": "SKwAKTcLSVV8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "QQ0mHfuuU9aM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XpaoGAcRZgzW",
        "outputId": "d1ce0818-eb53-4631-b141-fb22e5032bf2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                    text        label\n",
            "0      Parking position handling was not well address...       Design\n",
            "1                       The SDS of WH was not up-to-date       Design\n",
            "2                 Direct use of a trace definition file.  Integration\n",
            "3                 Patch too old, not traceable any more.  Integration\n",
            "4      Clearmake does not remove already build obsole...  Integration\n",
            "...                                                  ...          ...\n",
            "10735                                         SW design.       Design\n",
            "10736                                         SW design.       Design\n",
            "10737  A DDF timeout is not reported by the CN facili...  Realization\n",
            "10738  Automated regression does not capture the impa...       Design\n",
            "10739  The combination of file sizes, number of scann...        Other\n",
            "\n",
            "[10521 rows x 2 columns]\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, 199, 128)          899456    \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 128)               131584    \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 9)                 1161      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1032201 (3.94 MB)\n",
            "Trainable params: 1032201 (3.94 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "177/177 [==============================] - 118s 643ms/step - loss: 1.9117 - accuracy: 0.2692 - val_loss: 1.7334 - val_accuracy: 0.3858\n",
            "Epoch 2/5\n",
            "177/177 [==============================] - 111s 628ms/step - loss: 1.4210 - accuracy: 0.5129 - val_loss: 1.4600 - val_accuracy: 0.5163\n",
            "Epoch 3/5\n",
            "177/177 [==============================] - 105s 592ms/step - loss: 0.9700 - accuracy: 0.6748 - val_loss: 1.4966 - val_accuracy: 0.5248\n",
            "Epoch 4/5\n",
            "177/177 [==============================] - 111s 628ms/step - loss: 0.6734 - accuracy: 0.7863 - val_loss: 1.5665 - val_accuracy: 0.5567\n",
            "Epoch 5/5\n",
            "177/177 [==============================] - 105s 592ms/step - loss: 0.4870 - accuracy: 0.8436 - val_loss: 1.6415 - val_accuracy: 0.5589\n",
            "109/109 [==============================] - 8s 70ms/step - loss: 1.7546 - accuracy: 0.5259\n",
            "Test Accuracy: 52.59%\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "# Drop unnecessary columns and rename cols,\n",
        "# Assuming we need only 'text' and 'label' columns\n",
        "data = (pd.read_csv('RCA_V3.csv',sep=None,engine='python', usecols = ['RCA_Main_Root_Cause','RCA Defect Domain'])).dropna(how='all')\n",
        "data.columns = ['text', 'label']\n",
        "data.head()\n",
        "print(data)\n",
        "\n",
        "#Check for missing values\n",
        "missing_values = data.isnull().sum()\n",
        "\n",
        "\n",
        "# Step 6: Fill NaN in 'text' column with an empty string\n",
        "data['text'].fillna('', inplace=True)\n",
        "\n",
        "# Step 7: Create Feature and Label sets\n",
        "X = data['text']\n",
        "y = data['label']\n",
        "\n",
        "# Step 8: Assuming 'text' column may have NaN values, fill NaN with an empty string (Redundant)\n",
        "X.fillna('', inplace=True)\n",
        "\n",
        "# Step 9: Encode labels to integers\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "# Step 10: Train-test split (67% train - 33% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.33, random_state=42)\n",
        "\n",
        "# Step 11: Train Bag of Words model\n",
        "vectorizer = CountVectorizer()\n",
        "X_train_bow = vectorizer.fit_transform(X_train)\n",
        "X_test_bow = vectorizer.transform(X_test)\n",
        "\n",
        "# Step 12: Reverse the encoding to get original class labels\n",
        "original_labels = label_encoder.inverse_transform(y_encoded)\n",
        "\n",
        "# Step 13: Tokenization and padding\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
        "max_len = max(len(seq) for seq in X_train_seq)\n",
        "X_train_pad = pad_sequences(X_train_seq, maxlen=max_len)\n",
        "X_test_pad = pad_sequences(X_test_seq, maxlen=max_len)\n",
        "\n",
        "# Step 14: Convert labels to one-hot encoding using numpy\n",
        "y_train_oh = to_categorical(y_train)\n",
        "y_test_oh = to_categorical(y_test)\n",
        "\n",
        "# Step 15: Define RNN\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=vocab_size, output_dim=128, input_length=max_len))\n",
        "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(len(label_encoder.classes_), activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train_pad, y_train_oh, epochs=5, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test_pad, y_test_oh)\n",
        "print(f'Test Accuracy: {accuracy * 100:.2f}%')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "score, acc = model.evaluate(X_test_pad, y_test_oh, batch_size=32)\n",
        "print(\"Test score:\", score)\n",
        "print(\"Test accuracy:\", acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAscnM9aU9lv",
        "outputId": "a676fc65-2d44-490d-ccef-4f9efa8f8596"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "109/109 [==============================] - 10s 90ms/step - loss: 1.7546 - accuracy: 0.5259\n",
            "Test score: 1.7546255588531494\n",
            "Test accuracy: 0.525921642780304\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RCVFXSpTU9pE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LVX_tbZiU9sa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}